---
title: "R Notebook"
output: html_notebook
---
 
# Introduction

Steps:

1. "Save as..." file to a new meaningful name, including some indication of the data you're processing.
2. Edit ` paths ` and ` contrastPatterns` in Configuration section below, including options in "Prepare for artMS".
3. First run artMS/MSstats by running first  code blocks manually.
4. Do something useful while waiting for MSstats to finish (cup of coffee, say hi to your kids/parents, pet your dog).
5. Once MSstats is finished,  run the remaining blocks.  "Run All" from the Run menu is probably easiest.
6. Inspect artMS quality control plots (in ` outputDirectory`) and the heatmap plots here for problems in the data.
7. Optionally, use "Knit to PDF" to make a nice record of what is done. 

Tips:

1. Modify code as needed to make thresholds etc as you want them; and rerun individual code blocks or lines.
2. Use `pdf` or `cairo_pdf` to make nice PDF files of individual plots suitable for figures. Some examples are included but commented out.




# Utility functions and library calls
Run this then jump to *Configuration* on line 113
```{r}
library (data.table)
library (ComplexHeatmap)
library (ggplot2)
rotate.x.axis.text <- theme(axis.text.x = element_text(angle = 90))


today <- function(){
  format(Sys.time(), "%Y_%m_%d")
}
DateFileName <- function(x){
  name <-   paste0(today(), "_", x)
  print (name)
  return (name)
}

ScriptNamedDir <- function(scriptName = NULL){
  if(is.null(scriptName))
    scriptName <- rstudioapi::getActiveDocumentContext()$path
  if (is.null (scriptName) || scriptName == "")
    stop("No script name found -- you may need to save this file first")
  outDir <- gsub(".R(md)?$", "_data", scriptName)
  if (!dir.exists(outDir)){
    message ("Creating directory associated with ", scriptName,", at ", outDir)
    dir.create(outDir)
  }
  return(outDir)
}


ScriptAndDatedFileName <- function(x, scriptName = NULL){
  dir <- ScriptNamedDir(scriptName)
  fileName <- DateFileName(x)
  path <- file.path(dir, fileName)
  print (path)
  return (path)
}

GetLatestScriptFile <- function(x, scriptName=NULL){
  stopifnot (length(x) == 1)
  dir <- ScriptNamedDir(scriptName)
  filePattern <- paste0("^\\d{4}_\\d{2}_\\d{2}_", x, "$", collapse = "")
  filesFound <- list.files(dir, filePattern)
  stopifnot (length(filesFound) > 0)
  if (length(filesFound) > 1){
    message ("Multiple files  with matching names found.  Using the last one")
    print (filesFound)
  }
  return (file.path(dir, tail(filesFound, 1)))
} 

PDFBackupFileName <- function(prefix = ""){
  scriptDir <- ScriptNamedDir()
  imageDir <- file.path(scriptDir, "pdfs")
  if (!dir.exists(imageDir)) dir.create(imageDir)
  now <- format(Sys.time(),  "%Y_%m_%d__%H_%M__%S")
  path <- file.path (imageDir, sprintf("%s%s.pdf", prefix, now))
  while (file.exists(path)){
    seconds <- unlist(strsplit (gsub("\\.pdf$", "", basename(path)), split = "_"))[8]
    seconds <- as.numeric(seconds) + 0.1
    path <- gsub ("[0-9.]+$", as.character(seconds), path)
  }
  return (path)
}

BackupAsPDF <- function(graphics, prefix = ""){
  path <- PDFBackupFileName(prefix)
  dimensions <- dev.size(units = "in")
  
  # handle my enrichment heatmaps that are part of a list
  if (! ("ggplot" %in% class(graphics) | "Heatmap" %in% class(graphics) | "HeatmapList" %in% class(graphics))){
    g <- graphics$hmList    
  }else{
    g <- graphics
  }
  
  print (sprintf("Writing image to  %s", path))
  cairo_pdf(path, width = dimensions[1], height = dimensions[2])
    print (g)
  dev.off()
  return (graphics)
}

```

# Configuration

```{r}
#the location on your computer where bp_utils can be found; clone or download from link at https://github.com/kroganlab
githubKroganLab <- "~/UCSF/kroganlab"

# the input data from spectronaut, in "MSstats" format or similar
spectronautPeptideFile <- "/Users/ben/Box/5HT2A data analysis/HTR7/PH/20210805_HTR7_PH_targetDIA_0_Report.xls" 

# if spectronautPeptidefile is set to NULL, set maxQuantFiles here...
maxQuantEvFile <- "/Users/ben/Box/5HT2A data analysis/5-HT/Phospho/DDA/evidence.txt"
keysFile <- "/Users/ben/Box/5HT2A data analysis/5-HT/Phospho/DDA/keys.txt"

# most output will appear within here (all?--that's the goal)
jobName <- "PH_work"
outputDirectory <- ScriptAndDatedFileName(jobName)

# don't change these (unless you know what you're doing):
outFilePrefix <- outputDirectory
dir.create( outFilePrefix, recursive = TRUE, showWarnings = FALSE)


# a list of regular expressions to select the contrasts from the full all-by-all set.  
# This will be used by the R function grep, so all regular expressions that it understands are allowed.
# set to NULL for a non-redundant (A-B but not B-A) all-by-all set
contrastPatterns <- c("(DMSO|Lis_..)-Lis_00", "(ACN|Psi_..)-Psi_00") #NULL #c("LSD.*-LSD_0", "LSD.*-ACN_60")

# path to the proteome fasta file that shouldl have all proteins mentioned in spectronaut.
# used by artMS to get sequence positions for PTM
referenceProteomeFasta <- "~/UCSF/kroganlab/BenPolacco/data/human_all_proteins_canonical_uniprot-proteome_UP000005640.fasta.gz"

# choose either PH or UB to match the data, "AB" for abundance workflow
site.PH_or_UB <- "PH"



# if you want to exclude runs or conditions, put them in these vectors
# a new input file will be written with these runs/conditions excluded
# here, run corresponds to Run column in the "spectronaut for MSstats" output
# it is the "RawFile" column in the keys.txt file

conditionsToSkip <- c()#("Ctrl_24Hr")
runsToSkip <- c() #c("LP1_11_phos_DIA_124.raw")





originalWorkingDirectory <- getwd()

if (length(conditionsToSkip) >0 | length(runsToSkip) > 0){
  if(is.null(spectronautPeptideFile)) stop("Not implemented for maxquant yet")
  a <- fread (spectronautPeptideFile)
  a <- a[ !(Condition %in% conditionsToSkip | Run %in% runsToSkip)]
  
  spectronautPeptideFile <- file.path(outputDirectory, "spectronaut_subset.csv")
  fwrite (a, spectronautPeptideFile)
  
  }

```



## Prepare for artMS

Some settings here in the `cf` list object

```{r}
source (file.path(githubKroganLab, "bp_utils", "spectronautFile2ArtMS.R"))

cf<- list()
# normalization method FALSE = no normalization; default is global medians which you can get my removing/commenting out all normalization lines
# cf$msstats$normalization_method = FALSE

#cf$msstats$normalization_method = "globalStandards"
#cf$msstats$normalization_reference <-  "P38398"

# should artms attempt to annotate proteins 1 = yes; 0 = no
cf$output_extras$annotate$enabled <- as.integer(0)
# should artms do extended QC 1 = yes; 0= no
cf$qc$extended <- as.integer(1)
cf$qc$basic <- as.integer(1)


```

# Filter spectronaut PH data using PTMAssayProbability

```{r}
if (!is.null(spectronautPeptideFile) & site.PH_or_UB != "AB"){
  filteredSpecFile <- ScriptAndDatedFileName("SpectronautFeaturesPTMProbFiltered.csv")
  if(!file.exists(filteredSpecFile)){
    specFile <- fread (spectronautPeptideFile)
    
    # mark frequnetly observed features (>10 observations) as halfcomplete or not.
    # halfComplete == when observed, it must be prob>0.75 more than half the time
    halfCompleteSet <- specFile[, .(totalObs = .N, numPass0.75 = sum(EG.PTMAssayProbability > 0.75)), by = .(ProteinName, PeptideSequence, PrecursorCharge)][numPass0.75 > totalObs/2 & totalObs > 10]
    specFile[halfCompleteSet, halfComplete := TRUE, on = c("ProteinName", "PeptideSequence", "PrecursorCharge")]
    # we accept all things with prob > 0.75 but additionally those that are "halfComplete" regardless of prob 
    fwrite (specFile[EG.PTMAssayProbability > 0.75 | halfComplete == TRUE],  filteredSpecFile)
    spectronautPeptideFile <- filteredSpecFile
  }
}
```



# run artMS,including QC and MSstats
These steps have to be run manually.  `eval=FALSE` in their headings mean it won't be run while `knit`ting or by choosing "Run All". 

## make files in artMS format
```{r, eval = FALSE}
if(!is.null(spectronautPeptideFile)){
  globalInput <- spectronautFile2ArtMS(spectronautPeptideFile, outFilePrefix = outFilePrefix, artmsConfig = cf, contrastPatterns  = contrastPatterns)
  
} else{
  globalInput <- maxQuantFiles2ArtMS (maxQuantEvFile, keysFile, outFilePrefix = outFilePrefix, artmsConfig = cf, contrastPatterns  = contrastPatterns)
}
# If you don't like the contrasts, go back and change them now before proceeding.
```

```{r, eval = FALSE}
if(site.PH_or_UB %in% c("PH", "UB")){
  phosphoInput <- doSiteConversion (globalInput, referenceProteome = referenceProteomeFasta, site=site.PH_or_UB)
}

# artMS dumps a ton of files in current working directory.  Try to keep this clean by
# changing working directory to the _output directory.  
setwd(file.path(outFilePrefix, "output"))
if(site.PH_or_UB %in% c("PH", "UB")){
  artmsQuantification (phosphoInput$config_file)
} else{
  artmsQuantification (globalInput$config_file)
  
}

setwd(originalWorkingDirectory)

```

### only needed if groupComparison fails
If you got errors from `artMSQuantification`, and you see a results_RunLevelData.txt file but not a results.txt file, this code is for you.  Un-comment and run all lines.
This is also useful if you want to change the contrasts, in which case you should edit the contrasts file beforehand.

```{r, eval = FALSE}
# source (file.path (githubKroganLab, "bp_utils", "MSstats_Helper_Functions.R"))
# 
# mss.normalized.txt <-file.path(outputDirectory, "output", "results-mss-normalized.txt")
# protQuant.txt <- file.path(outputDirectory, "output", "results_RunLevelData.txt")
# mssQuant <- loadProcessedDataFromArtMS(mss.normalized.txt, protQuant.txt )
# 
# 
# contrasts.txt <- file.path (outputDirectory, "contrasts.txt")
# contrast.mat <- makeContrast.artMSFile(contrasts.txt)
# 
# results <- MSstats::groupComparison(contrast.mat, mssQuant)
# 
# fwrite (results$ComparisonResult, file.path (outputDirectory, "output", "results.txt"))
```



```{r}

outputDirectory <- GetLatestScriptFile(jobName)


# paths defined for the various files used in analyses below here:
results.txt <- file.path(outputDirectory, "output", "results.txt") 
mss.normalized.txt <-file.path(outputDirectory, "output", "results-mss-normalized.txt") 
protQuant.txt <- file.path(outputDirectory, "output", "results_RunLevelData.txt") 
# 
# previousDate <- "2020_10_26" # change this if you did the above on a different day and simply didn't rerun artMSQuantification
# 
# # first try with today's date, if it fails use previousDate
 #if(!file.exists ( results.txt) ){
   
#   outFilePrefix <- file.path(outputDirectory, sprintf("%s_%s", previousDate, jobPrefix ))
#   
#   results.txt <- file.path(outFilePrefix, "output",  "results.txt")
#   if(!file.exists ( results.txt) ){
#     stop("no results file found at ", results.txt)
#   }
#   
#   mss.normalized.txt <- file.path(outFilePrefix, "output", "results-mss-normalized.txt") 
#   protQuant.txt <- file.path(outFilePrefix, "output",  "results_RunLevelData.txt") 
# }

stopifnot(file.exists(results.txt))
message ("using output files associated with ", results.txt)  
```



# Volcanoes


```{r, fig.width=5, fig.height=7}
results <- fread (results.txt)

pvalueThreshold <- 0.05
log2FCThreshold <- 1
pvalueVariable <-  "adj.pvalue" # or "pvalue"


results[,sig := "not"]
results[results[[pvalueVariable]] < pvalueThreshold & abs(log2FC) > log2FCThreshold, sig := ifelse(log2FC  <0, "down", "up")]
results[, yVariable := -log10(results[[pvalueVariable]])]

p <- ggplot (results, aes(x=log2FC, y = yVariable, color = sig)) + 
  geom_point(show.legend = FALSE, alpha = 0.5, size = 1, shape = 16) + 
  facet_wrap (~Label) + 
  scale_color_manual(values = c(down= "blue", not = "gray", up = "red")) +
  #scale_x_continuous(limits = c(-4,4)) +
  scale_y_continuous(name = paste(pvalueVariable, "(-log10)", collapse = "")) +
  geom_hline(yintercept = -log10(pvalueThreshold), lty="dotted") +
  geom_vline(xintercept = c(-1, 1) * log2FCThreshold, lty="dotted") + 
  theme_bw() 


BackupAsPDF (p, "Volcanos_")


results[,c("posGroup", "negGroup") := tstrsplit(Label, split = "-")]

p <- ggplot (results, aes(x=log2FC, y = yVariable, color = sig)) + 
  geom_point(show.legend = FALSE, alpha = 0.5, size = 1, shape = 16) + 
  facet_grid(rows=vars(posGroup), cols = vars(negGroup)) + 
  scale_color_manual(values = c(down= "blue", not = "gray", up = "red")) +
  #scale_x_continuous(limits = c(-4,4)) +
  scale_y_continuous(name = paste(pvalueVariable, "(-log10)", collapse = "")) +
  geom_hline(yintercept = -log10(pvalueThreshold), lty="dotted") +
  geom_vline(xintercept = c(-1, 1) * log2FCThreshold, lty="dotted") + 
  theme_bw() 


BackupAsPDF (p, "Volcanos_grid_")


```




# Do we trust normalization?
Basic approach here is to look at the high intensity, consistently observed petides and ask if they look normalized based on medians.
Edit minDisplayedIntensity to explore
```{r}
#mss.normalized.txt <-file.path(paste0(outFilePrefix, "_output", collapse=""), "results-mss-normalized.txt") 
normPepInt <- fread (mss.normalized.txt)

minDisplayedIntensity <- 2^10
observationCounts <- normPepInt[!is.na(INTENSITY) & INTENSITY > minDisplayedIntensity,.N, by = PEPTIDE]

ggplot (observationCounts, aes(x=N)) + geom_bar() +
  xlab("Count runs") + ylab("Count peptide ions") +
  labs(title = "How many peptide ions are detected in all/most runs?")

# If there are enough complete cases, just look at those
numRunsRequired <- max (observationCounts$N)
# or choose another number close to complete:
# numRunsRequired <- max (normPepInt[!is.na(INTENSITY),.N, by = PEPTIDE]$N) -2 
completePeptideIons <- observationCounts[ N >= numRunsRequired,]$PEPTIDE

ggplot (normPepInt[PEPTIDE %in% completePeptideIons], aes(x=interaction(GROUP_ORIGINAL, SUBJECT_ORIGINAL), y = ABUNDANCE)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(title = sprintf("%d peptide ions detected in at least %d runs with intensity > %d", length(completePeptideIons), numRunsRequired, minDisplayedIntensity))
        


```



# Heatmap view of peptide intensity

```{r, fig.width =6, fig.height=8}
#mss.normalized.txt <-file.path(paste0(outFilePrefix, "_output", collapse=""), "results-mss-normalized.txt") 
normPepInt <- fread (mss.normalized.txt)

normPepInt[, logCenteredIntensity := log2(INTENSITY/(median(INTENSITY, na.rm=TRUE))), by = PEPTIDE]
normInt.mat <- as.matrix(dcast(normPepInt, PEPTIDE~GROUP_ORIGINAL+SUBJECT_ORIGINAL, value.var = "logCenteredIntensity"), rownames = "PEPTIDE")

# subset to complete cases
normInt.mat <- normInt.mat[complete.cases(normInt.mat),]  # select rows with no missing values

if (nrow(normInt.mat) > 2000){
  normInt.mat <- normInt.mat[sample(nrow(normInt.mat), 1000),]  # select 1000 rows
}


normInt.mat.noNA <- normInt.mat
normInt.mat.noNA[is.na(normInt.mat.noNA)] <- quantile(normInt.mat, 0.001, na.rm=TRUE)
ddr <- as.dendrogram(hclust(dist(normInt.mat.noNA)))


Heatmap(normInt.mat, cluster_rows = ddr, show_row_names = FALSE,
        name = "log2.norm.int",
        col = circlize::colorRamp2(breaks = c(-2, 0, 2), colors = c("blue", "white", "red")))
Heatmap(normInt.mat, cluster_rows = ddr, show_row_names = FALSE,
        name = "log2.norm.int",
        col = circlize::colorRamp2(breaks = c(-2, 0, 2), colors = c("blue", "white", "red")),
        cluster_columns = FALSE, row_title = sprintf("%d peptides", nrow(normInt.mat)))

```

```{r, fig.width = 8, fig.height = 6}
normPepInt <- fread (mss.normalized.txt)

normPepInt[, logCenteredIntensity := log2(INTENSITY/(median(INTENSITY, na.rm=TRUE))), by = PEPTIDE]
normInt.mat <- as.matrix(dcast(normPepInt, PEPTIDE~GROUP_ORIGINAL+SUBJECT_ORIGINAL, value.var = "logCenteredIntensity"), rownames = "PEPTIDE")

# subset to complete cases
normInt.mat <- normInt.mat[complete.cases(normInt.mat),]  # select rows with no missing values



colInfo <- data.table(colname = colnames(normInt.mat))
# something like, this depends on the structure of your condition names
colInfo[,c("treat", "time", "rep") := tstrsplit(colname, "[_.]", keep = c(1,2,5)) ]




title <- NULL
#PCA
pcaOut <- prcomp(t(normInt.mat))
pcaDT <- as.data.table(pcaOut$x, keep.rownames=TRUE)

pcaPercentVar <- round(100 * (pcaOut$sdev^2)/sum(pcaOut$sdev^2), 1)

pcaDT <- merge (pcaDT, colInfo, by.x = "rn", by.y = "colname", all.x = TRUE)

#plot first two components
p <- ggplot (pcaDT, aes(x=PC1, y=PC2, color=rep, fill = time, shape = treat)) + 
  geom_point(alpha=1.0, size=4) + 
  ggrepel::geom_text_repel(aes(label=rn), show.legend = FALSE, size = 3) +
  theme_bw() + 
  xlab (sprintf ("PC1, %.1f%%", pcaPercentVar[1])) + 
  ylab (sprintf ("PC2, %.1f%%", pcaPercentVar[2])) + 
  ggtitle (sprintf ("PCA %s using %d features (log intensity)", title, nrow(normInt.mat))) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  scale_shape_manual(values = 21:25) +
  #scale_fill_manual(values = c(`05` = "gray", `30` = "black")) +
  guides(fill = guide_legend(override.aes = list(shape =21) ) ,
         color = guide_legend(override.aes = list(shape =21) ) )
BackupAsPDF(p, "PCA_Complete_Features")


# or basic

p <- ggplot (pcaDT, aes(x=PC1, y=PC2, label = rn)) + 
  geom_point(alpha=1.0, size=4) + 
  ggrepel::geom_text_repel(aes(label=rn), show.legend = FALSE, size = 3) +
  theme_bw() + 
  xlab (sprintf ("PC1, %.1f%%", pcaPercentVar[1])) + 
  ylab (sprintf ("PC2, %.1f%%", pcaPercentVar[2])) + 
  ggtitle (sprintf ("PCA %s using %d features (log intensity)", title, nrow(normInt.mat)))
  # scale_color_brewer(type = "qual", palette = "Dark2") +
  # scale_shape_manual(values = 21:25) +
  # #scale_fill_manual(values = c(`05` = "gray", `30` = "black")) +
  # guides(fill = guide_legend(override.aes = list(shape =21) ) ,
  #        color = guide_legend(override.aes = list(shape =21) ) )
BackupAsPDF(p, "PCA_Basic_Complete_Features")
```



# Kinase analysis

```{r}
source(file.path(githubKroganLab,  "bp_utils" ,"KinaseActivityScores.R"))
kinaseData <- loadKinaseData(file.path(githubKroganLab, "bp_utils", "data", "kinaseSiteList_BachmanGyoriSorger2019.csv.gz"))[]


#load MSstats results data
#results.txt <- file.path(paste0(outFilePrefix, "_output", collapse=""), "results.txt")
results <- fread (results.txt)

# convert to single site info based on gene names
source(file.path(githubKroganLab,  "bp_utils" ,"UniprotIDMapping.R"))
results[,gene := multiUniprotSites2multiGeneSites(Protein)]
singleSiteResults <- prepare_AMSS_ResultsFile(results, column = "gene")

labels <- unique(singleSiteResults$Label)
#kinAct <- kinaseActivity (expanded2SingleSites[Label == labels[4]])

kinActList <- lapply (labels, FUN=function(lab){kinaseActivity(singleSiteResults[Label == lab & representative==TRUE],
                                                               plots = FALSE,
                                                               kinaseData = kinaseData)})
names(kinActList) <- labels

kinActFull.scores <- rbindlist(lapply(kinActList, FUN = function(x)x$scores), idcol="Label")
kinActFull.mapped <- rbindlist(lapply(kinActList, FUN = function(x)x$kinaseMapped)) # Label is already in these tables

kinaseSummaryScores.csv <- ScriptAndDatedFileName("kinaseSummaryScores.csv")
kinaseSubstrateData.csv <- ScriptAndDatedFileName("kinaseSubstrateData.csv")
message (sprintf("Writing kinase output files to\n\t%s\n\t%s", kinaseSummaryScores.csv, kinaseSubstrateData.csv))

fwrite (kinActFull.scores, kinaseSummaryScores.csv)
fwrite (kinActFull.mapped, kinaseSubstrateData.csv)

```

## Heatmap of significant kinases
```{r, fig.width = 6, fig.height= 9}
sigKinases <-  kinActFull.scores[fdr.BH < 0.05 & N >= 2, unique(CTRL_GENE_NAME)]

sigKinase.mat.z <- as.matrix(dcast (kinActFull.scores[CTRL_GENE_NAME %in% sigKinases], CTRL_GENE_NAME~Label, value.var = "Z"),
                              rownames = "CTRL_GENE_NAME")

sigKinase.mat.N <- as.matrix(dcast (kinActFull.scores[CTRL_GENE_NAME %in% sigKinases], CTRL_GENE_NAME~Label, value.var = "N"),
                                  rownames = "CTRL_GENE_NAME")


hm <- Heatmap (sigKinase.mat.z, 
         cluster_columns=TRUE, 
         name = "Kinase Z Score",
         column_split = tstrsplit(colnames(sigKinase.mat.z), split="[-_.]")[[1]],
         col = circlize::colorRamp2(breaks = c(-3, 0, 0, 3), colors = c("blue", "gray", "gray", "red")),  # two midpoints in case you want to have a wider gray bar around 0
         cell_fun = function(j, i, x, y, width, height, fill) {
                                  if (!is.na(sigKinase.mat.N[i,j])){
                                    grid.text(sprintf("%.0f", sigKinase.mat.N[i, j]), x, y, gp = gpar(fontsize=10, col="white"))
                                  }
                                })

BackupAsPDF(hm, prefix = "Heatmap_SigKinases")

hm <- Heatmap (sigKinase.mat.z, 
         cluster_columns=FALSE, 
         name = "Kinase Z Score",
         column_split = tstrsplit(colnames(sigKinase.mat.z), split="[-_.]")[[1]],
         col = circlize::colorRamp2(breaks = c(-3, 0, 0, 3), colors = c("blue", "gray", "gray", "red")),  # two midpoints in case you want to have a wider gray bar around 0
         cell_fun = function(j, i, x, y, width, height, fill) {
                                  if (!is.na(sigKinase.mat.N[i,j])){
                                    grid.text(sprintf("%.0f", sigKinase.mat.N[i, j]), x, y, gp = gpar(fontsize=10, col="white"))
                                  }
                                })

BackupAsPDF(hm, prefix = "Heatmap_SigKinases_noColCluster")


```


## plots of individual kinase substrates


```{r, fig.width=8, fig.height=8}
BarplotKinaseActivities(kinActFull.scores, kinActFull.mapped, sigKinases = sigKinases)

BarplotKinaseActivities(kinActFull.scores, kinActFull.mapped, sigKinases = sigKinases, reverse=TRUE)

```

# Enrichment analysis
## Prepare sets of proteins from our data
```{R}
#load MSstats results data
#results.txt <- file.path(paste0(outFilePrefix, "_output", collapse=""), "results.txt") 
results <- fread (results.txt)
results[,sig := "not"]
results[pvalue < 0.01 & abs(log2FC) > 1, sig := ifelse(log2FC  <0, "down", "up")]

source (file.path(githubKroganLab, "bp_utils", "KinaseActivityScores.R"))
results <- expandProteinToSingleSites(results)

source (file.path(githubKroganLab, "bp_utils", "UniprotIDMapping.R"))
results[, gene := translateUniprot2GeneName(singleProtein, species = "HUMAN")]

geneGroups <- unique(results[sig != "not" & is.finite(log2FC), .(gene, group = Label)])
universe <- unique(results$gene)

```


## load gene ontology data
```{R}
source (file.path(githubKroganLab, "bp_utils", "enrichmentTestFunctions.R"))

gmt <- loadGmtFromBioconductor(dbName = "org.Hs.eg.db", ontology = "ALL", keyType = "SYMBOL")

```
## run enrichment tests
```{r}
library (parallel)
library (pbapply)
library (clusterProfiler)

groups <- unique(geneGroups$group)


numProcessors <- 1
# pblapply can use multiple processors if you set this above 1;
# I have mixed results, it looks like there is a lot of overhead
# you definitely don't want to max out your cores
#numProcessors <- floor(parallel::detectCores()/2)

message ("Computing enrichments on ", length(groups), " groups")
enrichList <-  pblapply(groups, 
                        function(g){
                          setDT(as.data.frame(enricher(unique(geneGroups[group==g,gene]),
                                                       pAdjustMethod="fdr",
                                                       universe=universe,
                                                       TERM2GENE = gmt,
                                                       qvalueCutoff = 1.1,
                                                       pvalueCutoff = 1.1)))
                        },
                        cl=numProcessors)
names(enrichList) <- groups

enrichTable <-  rbindlist(enrichList, idcol="group")
```

## simplify (remove redundancy between GO terms)
```{r}
simp <- simplifyEnrichBySimilarUniverseMembership(enrichTable, gmt, groupColumn="group",cutHeight = 0.99, broadest=FALSE, max_pAdjust = 0.1)

```

## plot
```{r, fig.height=4, fig.width=8}

a <- enrichHeatmapBestPerGroup(simp[[1]], simp[[2]],
                          #cols = sort(c(negCols, posCols)),
                          #negCols = negCols,
                          groupColumn = "group",
                          topN = 8,
                          cluster_columns=FALSE, 
                          reduceRedundantsAcrossGroups=TRUE,
                          minCount = 1,
                          max_pAdjust = 0.1)

# to draw results to a file; you will want to play with height and width to get reasonably shaped plot
# cairo_pdf("My_enrichment_heatmap_file.pdf", height=6, width=8)  # or replace cairo_pdf with pdf if you don't have cairo installed
# draw (a$hmList)
# dev.off()


BackupAsPDF(a, "PH_Protein_enrichments")
```